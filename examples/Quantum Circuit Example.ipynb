{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Using Sycamore Quantum Circuit\n",
    "\n",
    "Here we'll run through a more in-depth tensor contraction path finding, including all the different visualization options, by computing some amplitudes for random circuits on Google's Sycamore chip .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quimb.tensor as qtn\n",
    "import cotengra as ctg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just set up some misc notebook plotting stuff\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Sycamore circuit definitions are included in this repository, the first of which ($m=10$) should fit into memory, and the second of which ($m=12$) will require *slicing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_circuit(\n",
    "    n=53,\n",
    "    depth=10,\n",
    "    seed=0 ,\n",
    "    elided=0,\n",
    "    sequence='ABCDCDAB',\n",
    "    swap_trick=False\n",
    "):\n",
    "    file = f'circuit_n{n}_m{depth}_s{seed}_e{elided}_p{sequence}.qsim'\n",
    "\n",
    "    if swap_trick:\n",
    "        gate_opts={'contract': 'swap-split-gate', 'max_bond': 2}  \n",
    "    else:\n",
    "        gate_opts={}\n",
    "    \n",
    "    # instantiate the `Circuit` object that \n",
    "    # constructs the initial tensor network:\n",
    "    return qtn.Circuit.from_qasm_file(file, gate_opts=gate_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make our target tensor network the overlap of the wavefunction with a bitstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ = load_circuit(depth=20)\n",
    "psi_f = qtn.MPS_computational_state('0' * (circ.N))\n",
    "tn = circ.psi & psi_f\n",
    "output_inds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out what the raw TN looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn.graph(iterations=20, color=circ.psi.site_tags, legend=False, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as what it looks like after standard pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorNetwork1D(tensors=381, indices=754, L=53, max_bond=2)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace full simplify and cast to single precision\n",
    "tn.full_simplify_(output_inds=output_inds)\n",
    "tn.astype_('complex64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplification uses some `numba` compiled functions which might slow things done first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn.graph(initial_layout='kamada_kawai', iterations=10, color=circ.psi.site_tags, legend=False, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to try and find a contraction path (various initializiation options are illustrated - not necessarily the best):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc_kahypar-balanced', 'kahypar-balanced', 'cyc_kahypar', 'kahypar'],\n",
    "    max_repeats=500,\n",
    "    progbar=True,\n",
    "    minimize='size',#'flops\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer is stateful, so this following actual search call can be run repeatedly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the progress of the Bayesian optimizer like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 53.00 log10[FLOPs]: 18.90: 100%|██| 128/128 [02:48<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['kahypar'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 53.00 log10[FLOPs]: 24.08: : 500it [00:04, 100.83it/s]\n",
      "log2[SIZE]: 53.00 log10[FLOPs]: 18.89: : 500it [00:04, 114.71it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.70: 100%|██| 128/128 [02:18<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['kahypar-balanced'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.83: : 500it [00:05, 86.72it/s] \n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.67: : 500it [00:04, 109.10it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.68: 100%|██| 128/128 [02:14<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['kahypar-agglom'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.36: : 500it [00:05, 89.68it/s] \n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.68: : 500it [00:04, 113.34it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 20.07: 100%|██| 128/128 [02:39<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc_kahypar'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.29: : 500it [00:04, 105.90it/s]\n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 20.07: : 500it [00:05, 97.94it/s] \n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.82: 100%|██| 128/128 [02:16<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc_kahypar-balanced'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.67: : 500it [00:05, 92.49it/s] \n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.76: : 500it [00:04, 103.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')#,subtree_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.71: 100%|██| 128/128 [02:14<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc_kahypar-agglom'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    #slicing_reconf_opts={'target_size': 2**27, 'reconf_opts': {}},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.90: : 500it [00:05, 95.33it/s] \n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.70: : 500it [00:04, 109.49it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.61: 100%|██| 128/128 [05:35<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc2_kahypar'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.88: : 500it [00:06, 79.75it/s]\n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.59: : 500it [00:06, 77.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.40: 100%|██| 128/128 [05:52<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc2_kahypar-balanced'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 24.11: : 500it [00:04, 120.93it/s]\n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.39: : 500it [00:04, 117.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.70: 100%|██| 128/128 [02:17<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc2_kahypar-agglom'],\n",
    "    max_repeats=128,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    #slicing_reconf_opts={'target_size': 2**27, 'reconf_opts': {}},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log2[SIZE]: 52.00 log10[FLOPs]: 23.81: : 500it [00:04, 113.95it/s]\n",
      "log2[SIZE]: 52.00 log10[FLOPs]: 18.69: : 500it [00:04, 109.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tree = ctg.ContractionTree.from_info(info)\n",
    "tree_s = tree.subtree_reconfigure(progbar=True,minimize='size')\n",
    "tree_f = tree.subtree_reconfigure(progbar=True,minimize='flops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['cyc_kahypar', 'cyc_kahypar-balanced', 'cyc_kahypar-agglom', 'cyc2_kahypar', 'cyc2_kahypar-balanced', 'cyc2_kahypar-agglom', 'kahypar', 'kahypar-balanced', 'kahypar-agglom'],\n",
    "    max_repeats=1500,\n",
    "    progbar=True,\n",
    "    #optlib = 'random',\n",
    "    minimize='size',#'flops\n",
    "    reconf_opts={'minimize':'flops'},\n",
    "    score_compression=0.5,  # deliberately make the optimizer try many methods \n",
    ")\n",
    "info = tn.contract(all, optimize=opt, get='path-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.plot_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the `kahypar` optimizer seems to be able to find the lowest cost contractions.\n",
    "\n",
    "We can also plot the relationship between contraction flops and size (the `minimize='combo'` score (log2[SIZE] + log2[FLOPS]) effectively ranks how close they are to the origin and can be useful to balance the two aims):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.plot_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where it becomes apparent, that while correlated, the minimum size contraction found is not necessarily the same as the minimum cost contraction found.\n",
    "\n",
    "If we want to visualize what the actual best contraction tree looks like we need to extract the `ContractionTree` object from the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = opt.get_tree()\n",
    "tree.plot_ring(node_scale= 1 / 3, edge_scale=2 / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try and plot what this might look like on top of the TN graph arranged properly, though its likely messy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the contraction found is imbalanced, with small tensors being steadily absorbed into one big tensor.\n",
    "\n",
    "One more plot function allows one to investigate the actual numbers involved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_contractions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 'peak-size' is the memory required for both inputs and the output of each contraction.\n",
    "\n",
    "Note again that 'flops' defined here assumes real data (as per `opt_einsum` convention), the 'cost' or number of scalar operations, $C$, is generally half this, whereas for quantum circuits with complex tensors, the real FLOPs will be 4x.\n",
    "\n",
    "We can also actually perform the contraction (this is using a GTX 2070):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tn.contract(all, optimize=opt.path, backend='jax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tn.contract(all, optimize=opt.path, backend='torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TN construction and simplification is determinstic in `quimb` so at least in this case we can easily evaluate another amplitude with the same contraction tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = (circ.psi & qtn.MPS_rand_computational_state(circ.N, seed=42))\n",
    "tn.full_simplify_().astype_('complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tn.contract(all, optimize=opt.path, backend='jax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tn.contract(all, optimize=opt.path, backend='jax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for sliced contractions (Sycamore $m=12$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate slicing we'll setup a (much harder!) depth 12 circuit. We'll perform a swapped rank-2 decomposition on the gates (for a not insignificant drop in total fidelity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ = load_circuit(depth=12, swap_trick=True)\n",
    "sampler = qtn.MPS_computational_state('0' * (circ.N))\n",
    "tn = circ.psi & sampler\n",
    "tn.full_simplify_(output_inds=[])\n",
    "tn.astype_('complex64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the rank-2 swapped gate decomposition the full simplify function has now found hyperedge introducing diagonal reductions (which is why there are more tensors than indices).\n",
    "\n",
    "Now when we intialize the hyper optimizer we'll tell it slice each contraction before reporting the cost and size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to help accelerate the optimizer search by restricting its search space, \n",
    "# since highly balanced contraction trees generally slice best:\n",
    "ctg.hyper._HYPER_SEARCH_SPACE['kahypar']['imbalance']['max'] = 0.1\n",
    "\n",
    "opt = ctg.HyperOptimizer(\n",
    "    methods=['kahypar'],\n",
    "    max_time=120,              # just search for 2 minutes\n",
    "    max_repeats=1000,\n",
    "    progbar=True,\n",
    "    minimize='flops',\n",
    "    slicing_opts={'target_size': 2**28}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of the hyperedges we need to specify no output indices\n",
    "info = tn.contract(all, optimize=opt, get='path-info', output_inds=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliced contractions can be more difficult to find, if performance is critical its worth running this for longer, maybe with a large parallel pool supplied to the `parallel=` kwarg. \n",
    "\n",
    "We can see that all the contractions are now 'size 28' however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.plot_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check what this new contraction tree looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = opt.get_tree()\n",
    "tree.plot_ring(node_scale=1 / 3, edge_scale=2 / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As enforced, its now somewhat more balanced than the $m=10$ tree.\n",
    "\n",
    "Now we are ready to search properly for the slicing indices, $2^{28}$ should be small enough to fit into no more than 8GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = ctg.SliceFinder(info, target_size=2**28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do quite thorough search with different levels of exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_sl, cost_sl = sf.search(temperature=1.0)\n",
    "ix_sl, cost_sl = sf.search(temperature=0.1)\n",
    "ix_sl, cost_sl = sf.search(temperature=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise what effect the slicing has had on the total cost (left - starting point, further to the right equals more sliced):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot_slicings(color_scheme='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there seems to have been very little theoretical overhead introduced by the slicing, *for this path*. The real slicing overhead is the increase in FLOPs in comparison to best unsliced path (likely v different).\n",
    "\n",
    "\n",
    "## Performing the sliced contraction\n",
    "\n",
    "The order of `quimb` tensors and their data is guaranteed to match that used by the `opt_einsum` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [t.data for t in tn] \n",
    "sc = sf.SlicedContractor(arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could translate the opt_einsum symbols back into `quimb` indices to handle the contractions in tensor network form (and use ``.cut_iter``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[info.quimb_symbol_map[ix] for ix in ix_sl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time a contraction is run by `jax` with a particular shape its compiled, which can take a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'jax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "c = sc.contract_slice(0, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the sliced contraction stores the compiled expression and reuses it for each slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(1, sc.nslices)):\n",
    "    c = c + sc.contract_slice(i, backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the TN manipulations are deterministic so we can re-use everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = circ.psi & qtn.MPS_rand_computational_state(circ.N, seed=42)\n",
    "tn.full_simplify_(output_inds=[]).astype_('complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the SlicedContractor's arrays\n",
    "sc.arrays = tuple(t.data for t in tn)\n",
    "\n",
    "# perform the contraction\n",
    "sum(sc.contract_slice(i, backend=backend) for i in tqdm.tqdm(range(sc.nslices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the SlicedContractor's arrays\n",
    "sc.arrays = tuple(t.data for t in tn)\n",
    "\n",
    "# perform the contraction\n",
    "sum(sc.contract_slice(i, backend=backend) for i in tqdm.tqdm(range(sc.nslices)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
